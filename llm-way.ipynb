{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9562344,"sourceType":"datasetVersion","datasetId":5827400}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install cohere","metadata":{"execution":{"iopub.status.busy":"2024-10-08T06:09:52.571935Z","iopub.execute_input":"2024-10-08T06:09:52.572392Z","iopub.status.idle":"2024-10-08T06:10:31.192032Z","shell.execute_reply.started":"2024-10-08T06:09:52.572348Z","shell.execute_reply":"2024-10-08T06:10:31.190697Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting cohere\n  Downloading cohere-5.11.0-py3-none-any.whl.metadata (3.4 kB)\nCollecting boto3<2.0.0,>=1.34.0 (from cohere)\n  Downloading boto3-1.35.35-py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: fastavro<2.0.0,>=1.9.4 in /opt/conda/lib/python3.10/site-packages (from cohere) (1.9.4)\nRequirement already satisfied: httpx>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from cohere) (0.27.0)\nCollecting httpx-sse==0.4.0 (from cohere)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting parameterized<0.10.0,>=0.9.0 (from cohere)\n  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: pydantic>=1.9.2 in /opt/conda/lib/python3.10/site-packages (from cohere) (2.9.2)\nRequirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /opt/conda/lib/python3.10/site-packages (from cohere) (2.23.4)\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from cohere) (2.32.3)\nCollecting sagemaker<3.0.0,>=2.232.1 (from cohere)\n  Downloading sagemaker-2.232.2-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: tokenizers<1,>=0.15 in /opt/conda/lib/python3.10/site-packages (from cohere) (0.20.0)\nCollecting types-requests<3.0.0,>=2.0.0 (from cohere)\n  Downloading types_requests-2.32.0.20240914-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: typing_extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from cohere) (4.12.2)\nCollecting botocore<1.36.0,>=1.35.35 (from boto3<2.0.0,>=1.34.0->cohere)\n  Downloading botocore-1.35.35-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.0->cohere) (1.0.1)\nCollecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere)\n  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (4.4.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (3.7)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9.2->cohere) (0.7.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere) (1.26.18)\nRequirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (23.2.0)\nCollecting cloudpickle==2.2.1 (from sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: docker in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (7.1.0)\nRequirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (0.2.0)\nCollecting importlib-metadata<7.0,>=1.4.0 (from sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (4.22.0)\nRequirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (21.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (2.2.3)\nRequirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (0.3.3)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (3.11.0)\nRequirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (3.20.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (5.9.3)\nRequirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (6.0.2)\nCollecting sagemaker-core<2.0.0,>=1.0.0 (from sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading sagemaker_core-1.0.10-py3-none-any.whl.metadata (4.9 kB)\nCollecting sagemaker-mlflow (from sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting schema (from sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\nCollecting smdebug-rulesconfig==1.0.1 (from sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\nCollecting tblib<4,>=1.7.0 (from sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere) (4.66.4)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers<1,>=0.15->cohere) (0.25.1)\nCollecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.0.0->cohere)\n  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.35->boto3<2.0.0,>=1.34.0->cohere) (2.9.0.post0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.6.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker<3.0.0,>=2.232.1->cohere) (3.19.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->sagemaker<3.0.0,>=2.232.1->cohere) (3.1.2)\nCollecting platformdirs (from sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere) (13.7.1)\nCollecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere) (0.18.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere) (1.2.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker<3.0.0,>=2.232.1->cohere) (1.16.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker<3.0.0,>=2.232.1->cohere) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker<3.0.0,>=2.232.1->cohere) (2024.1)\nRequirement already satisfied: ppft>=1.7.6.9 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere) (1.7.6.9)\nCollecting dill>=0.3.9 (from pathos->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: pox>=0.3.5 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere) (0.3.5)\nCollecting multiprocess>=0.70.17 (from pathos->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\nCollecting mlflow>=2.8 (from sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading mlflow-2.16.2-py3-none-any.whl.metadata (29 kB)\nCollecting mlflow-skinny==2.16.2 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading mlflow_skinny-2.16.2-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.0.3)\nRequirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.13.3)\nCollecting graphene<4 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.6)\nRequirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.7.5)\nRequirement already satisfied: pyarrow<18,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (17.0.0)\nRequirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.2.2)\nRequirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.14.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (2.0.30)\nRequirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.1.4)\nCollecting gunicorn<24 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nCollecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (8.1.7)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading databricks_sdk-0.34.0-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.1.43)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.25.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.25.0)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (0.5.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere) (2.18.0)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.3.5)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.0.4)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (2.2.0)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.8.2)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nCollecting aniso8601<10,>=8 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere)\n  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (2.1.5)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere) (0.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (10.3.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.5.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (3.0.3)\nRequirement already satisfied: google-auth~=2.0 in /opt/conda/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (2.30.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (4.0.11)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.2.14)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (0.46b0)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (1.16.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (5.0.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (4.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere) (0.6.0)\nDownloading cohere-5.11.0-py3-none-any.whl (249 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading boto3-1.35.35-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\nDownloading sagemaker-2.232.2-py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\nDownloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\nDownloading types_requests-2.32.0.20240914-py3-none-any.whl (15 kB)\nDownloading botocore-1.35.35-py3-none-any.whl (12.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\nDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sagemaker_core-1.0.10-py3-none-any.whl (388 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.4/388.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\nDownloading tblib-3.0.0-py3-none-any.whl (12 kB)\nDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\nDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\nDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mlflow-2.16.2-py3-none-any.whl (26.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-2.16.2-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mock-4.0.3-py3-none-any.whl (28 kB)\nDownloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\nDownloading databricks_sdk-0.34.0-py3-none-any.whl (565 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.6/565.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nInstalling collected packages: schema, aniso8601, urllib3, tblib, smdebug-rulesconfig, platformdirs, parameterized, mock, importlib-metadata, httpx-sse, graphql-core, dill, cloudpickle, cachetools, types-requests, multiprocess, gunicorn, graphql-relay, botocore, s3transfer, graphene, databricks-sdk, boto3, sagemaker-core, mlflow-skinny, mlflow, sagemaker-mlflow, sagemaker, cohere\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: platformdirs\n    Found existing installation: platformdirs 3.11.0\n    Uninstalling platformdirs-3.11.0:\n      Successfully uninstalled platformdirs-3.11.0\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 7.0.0\n    Uninstalling importlib-metadata-7.0.0:\n      Successfully uninstalled importlib-metadata-7.0.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: cloudpickle\n    Found existing installation: cloudpickle 3.0.0\n    Uninstalling cloudpickle-3.0.0:\n      Successfully uninstalled cloudpickle-3.0.0\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 4.2.4\n    Uninstalling cachetools-4.2.4:\n      Successfully uninstalled cachetools-4.2.4\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.35.23\n    Uninstalling botocore-1.35.23:\n      Successfully uninstalled botocore-1.35.23\n  Attempting uninstall: s3transfer\n    Found existing installation: s3transfer 0.6.2\n    Uninstalling s3transfer-0.6.2:\n      Successfully uninstalled s3transfer-0.6.2\n  Attempting uninstall: boto3\n    Found existing installation: boto3 1.26.100\n    Uninstalling boto3-1.26.100:\n      Successfully uninstalled boto3-1.26.100\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.15.1 requires botocore<1.35.24,>=1.35.16, but you have botocore 1.35.35 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.9 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.3 which is incompatible.\ncesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nconda 24.9.0 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\ndask 2024.9.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\ndatasets 3.0.1 requires dill<0.3.9,>=0.3.0, but you have dill 0.3.9 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.3 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nvirtualenv 20.21.0 requires platformdirs<4,>=2.4, but you have platformdirs 4.3.6 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed aniso8601-9.0.1 boto3-1.35.35 botocore-1.35.35 cachetools-5.3.3 cloudpickle-2.2.1 cohere-5.11.0 databricks-sdk-0.34.0 dill-0.3.9 graphene-3.3 graphql-core-3.2.4 graphql-relay-3.2.0 gunicorn-23.0.0 httpx-sse-0.4.0 importlib-metadata-6.11.0 mlflow-2.16.2 mlflow-skinny-2.16.2 mock-4.0.3 multiprocess-0.70.17 parameterized-0.9.0 platformdirs-4.2.2 s3transfer-0.10.2 sagemaker-2.232.2 sagemaker-core-1.0.10 sagemaker-mlflow-0.1.0 schema-0.7.7 smdebug-rulesconfig-1.0.1 tblib-3.0.0 types-requests-2.32.0.20240914 urllib3-2.2.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import cohere\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport random\nimport string\nimport time\nfrom typing import List, Dict, Tuple\nimport os\nfrom collections import defaultdict\n\nclass LLMReviewGenerator:\n    def __init__(self, cohere_api_key: str, products_df: pd.DataFrame, reviews_df: pd.DataFrame):\n        self.co = cohere.Client(cohere_api_key)\n        \n        # Extract patterns from existing data\n        self.category_chains = self._extract_category_chains(products_df)\n        self.review_patterns = self._analyze_review_patterns(reviews_df)\n        \n        self.reviews_df = reviews_df\n        \n        print(f\"Extracted {len(self.category_chains)} unique category chains\")\n        print(f\"Analyzed review patterns across {len(reviews_df)} reviews\")\n        \n    def _extract_category_chains(self, df: pd.DataFrame) -> List[Dict[str, str]]:\n        \"\"\"Extract all unique category chains from the products dataframe\"\"\"\n        category_columns = ['categories', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6']\n        \n        # Get unique category combinations\n        unique_categories = df[category_columns].drop_duplicates()\n        \n        # Convert to list of dictionaries\n        category_chains = unique_categories.to_dict('records')\n        \n        # Remove any None or NaN values\n        cleaned_chains = []\n        for chain in category_chains:\n            cleaned_chain = {\n                k: str(v) for k, v in chain.items() \n                if v is not None and pd.notna(v) and str(v).lower() != 'nan'\n            }\n            if cleaned_chain:\n                cleaned_chains.append(cleaned_chain)\n        \n        return cleaned_chains\n\n    def _analyze_review_patterns(self, reviews_df: pd.DataFrame) -> Dict:\n        \"\"\"Analyze patterns in existing reviews to inform generation\"\"\"\n        patterns = {\n            'rating_distribution': reviews_df['rating'].value_counts(normalize=True).to_dict(),\n            'avg_helpful_votes': reviews_df['helpful_vote'].mean(),\n            'verified_purchase_ratio': reviews_df['verified_purchase'].mean(),\n            'review_length_stats': {\n                'title_length': {\n                    'mean': reviews_df['title'].str.len().mean(),\n                    'std': reviews_df['title'].str.len().std()\n                },\n                'text_length': {\n                    'mean': reviews_df['text'].str.len().mean(),\n                    'std': reviews_df['text'].str.len().std()\n                }\n            },\n            'temporal_patterns': {\n                'hour_distribution': reviews_df['time'].dt.hour.value_counts(normalize=True).to_dict(),\n                'weekday_distribution': reviews_df['date'].dt.dayofweek.value_counts(normalize=True).to_dict()\n            },\n            'reviews_per_product': reviews_df.groupby('parent_asin').size().agg(['mean', 'std']).to_dict()\n        }\n        \n        return patterns\n\n    def generate_product_prompt(self, category_chain: Dict[str, str]) -> str:\n        category_path = []\n        for cat in ['categories', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6']:\n            if category_chain.get(cat):\n                category_path.append(str(category_chain[cat]))\n        \n        category_str = \" > \".join(category_path)\n        \n        return f\"\"\"Generate a realistic product title and description for an item in this category path: {category_str}\n        Make it specific and detailed, matching the category exactly.\n        Format: \n        Title: [Product Title]\n        Description: [Product Description]\"\"\"\n\n    def generate_review_prompt(self, product_title: str, category_chain: Dict[str, str], rating: int) -> str:\n        sentiment = \"positive\" if rating > 3 else \"negative\" if rating < 3 else \"neutral\"\n\n        # Get average review length for this rating\n        target_length = int(self.review_patterns['review_length_stats']['text_length']['mean'])\n\n        # Sample a few existing reviews with similar sentiment to guide the generated review\n        existing_reviews = self._sample_existing_reviews(sentiment)\n        example_reviews = \"\\n\".join([f\"- {review}\" for review in existing_reviews])\n\n        category_context = [str(category_chain['categories'])]\n        if category_chain.get('cat1'):\n            category_context.append(str(category_chain['cat1']))\n        if category_chain.get('cat2'):\n            category_context.append(str(category_chain['cat2']))\n\n        category_str = \" - \".join(category_context)\n\n        return f\"\"\"Generate a realistic {sentiment} product review for: {product_title}\n        Product Category: {category_str}\n        The review should have a {rating} star rating out of 5 stars.\n        Make the review approximately {target_length} characters long.\n        Make it sound natural and include specific details about the product that make sense for its category.\n        Use similar style and tone as these examples:\n        {example_reviews}\n        Format:\n        Title: [Review Title]\n        Review: [Review Text]\"\"\"\n    \n    def _sample_existing_reviews(self, sentiment: str, num_samples: int = 3) -> List[str]:\n        \"\"\"Sample existing reviews from the dataset based on sentiment.\"\"\"\n        if sentiment == \"positive\":\n            filtered_reviews = self.reviews_df[self.reviews_df['rating'] > 3]['text']\n        elif sentiment == \"negative\":\n            filtered_reviews = self.reviews_df[self.reviews_df['rating'] < 3]['text']\n        else:\n            filtered_reviews = self.reviews_df[self.reviews_df['rating'] == 3]['text']\n\n        # Randomly sample a few reviews from the filtered set\n        sampled_reviews = filtered_reviews.sample(n=min(num_samples, len(filtered_reviews)), random_state=42).tolist()\n        return sampled_reviews\n    \n    def parse_llm_review_response(self, response_text: str) -> Dict[str, str]:\n        \"\"\"Parse the review title and text from the LLM response.\"\"\"\n        try:\n            lines = response_text.strip().split('\\n')\n            title_line = next((line for line in lines if line.startswith(\"Title:\")), \"Title: [Unknown Review]\")\n            review_line = next((line for line in lines if line.startswith(\"Review:\")), \"Review: [No Text]\")\n\n            title = title_line.replace(\"Title:\", \"\").strip()\n            review = review_line.replace(\"Review:\", \"\").strip()\n\n            return {'title': title, 'review': review}\n        except Exception as e:\n            print(f\"Error parsing LLM review response: {e}\")\n            return {'title': '[Error: Unable to parse title]', 'review': '[Error: Unable to parse review]'}\n    \n    def generate_products(self, num_products: int) -> pd.DataFrame:\n        \"\"\"Generate synthetic product data based on category chains.\"\"\"\n        products = []\n\n        for _ in range(num_products):\n            # Randomly choose a category chain for the product\n            category_chain = random.choice(self.category_chains)\n\n            # Generate product title and description using Cohere\n            prompt = self.generate_product_prompt(category_chain)\n\n            try:\n                response = self.co.generate(\n                    prompt=prompt,\n                    max_tokens=100,\n                    temperature=0.7,\n                    k=0,\n                    stop_sequences=[\"\\n\\n\"],\n                    return_likelihoods='NONE'\n                )\n\n                product_info = self.parse_llm_product_response(response.generations[0].text)\n\n                product = {\n                    'title': product_info['title'],\n                    'description': product_info['description'],\n                    'categories': category_chain.get('categories', ''),\n                    'cat1': category_chain.get('cat1', ''),\n                    'cat2': category_chain.get('cat2', ''),\n                    'cat3': category_chain.get('cat3', ''),\n                    'cat4': category_chain.get('cat4', ''),\n                    'cat5': category_chain.get('cat5', ''),\n                    'cat6': category_chain.get('cat6', ''),\n                    'parent_asin': ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))\n                }\n\n                products.append(product)\n\n                # Sleep to respect rate limits\n                time.sleep(0.5)\n\n            except Exception as e:\n                print(f\"Error generating product: {e}\")\n                continue\n\n        return pd.DataFrame(products)\n\n    def parse_llm_product_response(self, response_text: str) -> Dict[str, str]:\n        \"\"\"Parse the product title and description from the LLM response.\"\"\"\n        lines = response_text.strip().split('\\n')\n        title_line = next((line for line in lines if line.startswith(\"Title:\")), \"Title: [Unknown Product]\")\n        description_line = next((line for line in lines if line.startswith(\"Description:\")), \"Description: [No Description]\")\n\n        title = title_line.replace(\"Title:\", \"\").strip()\n        description = description_line.replace(\"Description:\", \"\").strip()\n\n        return {'title': title, 'description': description}\n\n    def generate_reviews(self, products_df: pd.DataFrame, max_reviews: int = 1000) -> pd.DataFrame:\n        data = []\n        total_reviews = 0  # Counter for the total number of reviews generated\n\n        for _, product in products_df.iterrows():\n            if total_reviews >= max_reviews:  # Stop if we've reached the maximum number of reviews\n                break\n\n            # Determine number of reviews for the current product\n            mean_reviews = self.review_patterns['reviews_per_product']['mean']\n            std_reviews = self.review_patterns['reviews_per_product']['std']\n            num_reviews = int(max(1, np.random.normal(mean_reviews, std_reviews)))\n\n            # Limit the number of reviews for the current product if necessary\n            num_reviews = min(num_reviews, max_reviews - total_reviews)\n\n            category_chain = {\n                col: product[col] for col in \n                ['categories', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6']\n            }\n\n            for _ in range(num_reviews):\n                try:\n                    # Generate rating based on learned distribution\n                    rating = np.random.choice(\n                        list(self.review_patterns['rating_distribution'].keys()),\n                        p=list(self.review_patterns['rating_distribution'].values())\n                    )\n\n                    # Generate review using Cohere\n                    response = self.co.generate(\n                        prompt=self.generate_review_prompt(\n                            product['title'],\n                            category_chain,\n                            rating\n                        ),\n                        max_tokens=200,\n                        temperature=0.8,\n                        k=0,\n                        stop_sequences=[\"\\n\\n\"],\n                        return_likelihoods='NONE'\n                    )\n\n                    review_info = self.parse_llm_review_response(response.generations[0].text)\n\n                    # Generate helpful votes based on learned patterns\n                    helpful_votes = max(0, int(np.random.normal(\n                        self.review_patterns['avg_helpful_votes'],\n                        self.review_patterns['avg_helpful_votes'] * 0.5\n                    )))\n\n                    # Generate verified purchase based on learned ratio\n                    verified_purchase = random.random() < self.review_patterns['verified_purchase_ratio']\n\n                    review = {\n                        'rating': rating,\n                        'title': review_info['title'],\n                        'text': review_info['review'],\n                        'asin': product['X'],\n                        'parent_asin': product['parent_asin'],\n                        'user_id': ''.join(random.choices(string.ascii_lowercase + string.digits, k=8)),\n                        'helpful_vote': helpful_votes,\n                        'verified_purchase': verified_purchase\n                    }\n\n                    data.append(review)\n                    total_reviews += 1  # Increment the total reviews counter\n\n                    # Sleep to respect rate limits\n                    time.sleep(0.5)\n\n                    if total_reviews >= max_reviews:  # Stop if we've reached the maximum number of reviews\n                        break\n\n                except Exception as e:\n                    print(f\"Error generating review: {e}\")\n                    continue\n\n        return pd.DataFrame(data)\n\n\n    def _generate_date_based_on_patterns(self) -> datetime.date:\n        \"\"\"Generate a date based on learned weekday distribution\"\"\"\n        weekday = np.random.choice(\n            list(self.review_patterns['temporal_patterns']['weekday_distribution'].keys()),\n            p=list(self.review_patterns['temporal_patterns']['weekday_distribution'].values())\n        )\n        \n        # Generate a date that falls on the chosen weekday\n        base_date = datetime(2020, 1, 1).date()\n        days_ahead = weekday - base_date.weekday()\n        if days_ahead <= 0:\n            days_ahead += 7\n        return base_date + timedelta(days=days_ahead)\n\n    def _generate_time_based_on_patterns(self) -> datetime.time:\n        \"\"\"Generate a time based on learned hour distribution\"\"\"\n        hour = np.random.choice(\n            list(self.review_patterns['temporal_patterns']['hour_distribution'].keys()),\n            p=list(self.review_patterns['temporal_patterns']['hour_distribution'].values())\n        )\n        minute = random.randint(0, 59)\n        second = random.randint(0, 59)\n        return datetime.strptime(f\"{hour}:{minute}:{second}\", \"%H:%M:%S\").time()\n\n    # ... (rest of the methods remain the same)\n\ndef main():\n    # Get Cohere API key from environment variable\n    cohere_api_key = \"1P0fk49DfMfiIiIxiMOdEOmE82crNyxBeeT2kG8H\"\n    if not cohere_api_key:\n        raise ValueError(\"Please set the COHERE_API_KEY environment variable\")\n    \n    # Load existing data\n    print(\"Loading existing data...\")\n    existing_products_df = pd.read_csv('/kaggle/input/assignment-reviews-metadata/product_asin.csv')\n    existing_reviews_df = pd.read_csv('/kaggle/input/assignment-reviews-metadata/reviews_supplements.csv', parse_dates=['date', 'time'])\n    \n    # Initialize generator with existing data\n    generator = LLMReviewGenerator(cohere_api_key, existing_products_df, existing_reviews_df)\n    \n    # Generate synthetic products\n#     print(\"Generating products...\")\n#     num_products = 10  # Start with a small number for testing\n#     products_df = generator.generate_products(num_products)\n#     print(products_df)\n    \n    # Generate synthetic reviews\n    print(\"Generating reviews...\")\n    reviews_df = generator.generate_reviews(existing_products_df, max_reviews=100)\n    print(reviews_df)\n    \n    # Save to CSV\n#     products_df.to_csv('synthetic_products.csv', index=False)\n    reviews_df.to_csv('synthetic_reviews.csv', index=False)\n    \n#     print(f\"Generated {len(products_df)} products and {len(reviews_df)} reviews\")\n#     print(\"Files saved as 'synthetic_products.csv' and 'synthetic_reviews.csv'\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-08T06:23:22.747362Z","iopub.execute_input":"2024-10-08T06:23:22.747899Z","iopub.status.idle":"2024-10-08T06:23:22.813886Z","shell.execute_reply.started":"2024-10-08T06:23:22.747853Z","shell.execute_reply":"2024-10-08T06:23:22.812740Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-10-08T06:23:31.649421Z","iopub.execute_input":"2024-10-08T06:23:31.649902Z","iopub.status.idle":"2024-10-08T06:30:16.881511Z","shell.execute_reply.started":"2024-10-08T06:23:31.649857Z","shell.execute_reply":"2024-10-08T06:30:16.880244Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Loading existing data...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/2657298167.py:317: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  existing_reviews_df = pd.read_csv('/kaggle/input/assignment-reviews-metadata/reviews_supplements.csv', parse_dates=['date', 'time'])\n","output_type":"stream"},{"name":"stdout","text":"Extracted 700 unique category chains\nAnalyzed review patterns across 16671 reviews\nGenerating reviews...\n    rating                                              title  \\\n0        5                                   [Unknown Review]   \n1        4                              A Miracle for Rashes!   \n2        5                                   [Unknown Review]   \n3        5                                   [Unknown Review]   \n4        5                                   [Unknown Review]   \n..     ...                                                ...   \n95       5  InvoSpa Shiatsu Back Shoulder and Neck Massage...   \n96       5  InvoSpa Shiatsu Back Shoulder and Neck Massage...   \n97       5  InvoSpa Shiatsu Back Shoulder and Neck Massage...   \n98       1                                   [Unknown Review]   \n99       1                                   [Unknown Review]   \n\n                                                 text  asin parent_asin  \\\n0   Allegra Allergy is a miracle! I've had issues ...     1  B00JENH5OI   \n1                                           [No Text]     1  B00JENH5OI   \n2   \"Finally, a product that works! I've been stru...     1  B00JENH5OI   \n3   \"This product works like a charm. I am very ha...     1  B00JENH5OI   \n4   \"Finally, a product that works! I've been stru...     1  B00JENH5OI   \n..                                                ...   ...         ...   \n95                                          [No Text]     2  B0C4L5Y711   \n96  I am a person who is constantly stressed and s...     2  B0C4L5Y711   \n97  This massage pillow is a game changer! I love ...     2  B0C4L5Y711   \n98                      Doesn't work. Waste of money.     2  B0C4L5Y711   \n99                      Doesn't work. Waste of money.     2  B0C4L5Y711   \n\n     user_id  helpful_vote  verified_purchase  \n0   k7flo4wv             1               True  \n1   8zg03oyj             2               True  \n2   9vo1eh57             1               True  \n3   04s0ny5b             2               True  \n4   xxk6honk             1               True  \n..       ...           ...                ...  \n95  vsv1vnfl             2               True  \n96  tgbnyria             2               True  \n97  dl9sh6ge             1               True  \n98  qp1vl0eh             0               True  \n99  ig8yqs61             1               True  \n\n[100 rows x 8 columns]\n","output_type":"stream"}]}]}